# This Program tests the Opex figures generated by Square. It compares the figures in the test MSQs to an opex creation model created by BB, and identifies cases for review.

import csv
import pandas as pd
import numpy as np
from pathlib import Path
import os
import re
import time
from fractions import Fraction
from IPython.core.display import display
pd.set_option('display.max_rows',  1000)
pd.set_option('display.max_columns', 100)

# Determine the first surveyed opex value for each id
def first_surv(data, variable):
    temp = data.copy()
    temp = temp[np.isnan(temp[variable]) == False]
    temp.sort_values(by=['totalmo'], ascending=True, inplace=True)
    temp = temp.drop_duplicates(['id'])
    temp = temp.set_index('id')
    temp = temp[[variable]]
    temp.columns = ['first_' + variable]
    data = data.join(temp, on = 'id')
    
    return data

# Determine the last surveyed opex value for each id and remove the periods after the last surveyed opex value, as those can be evaluated like the ids that have no opex quote at all
def last_surv(data, variable):
    temp = data.copy()
    temp = temp[np.isnan(temp[variable]) == False]
    temp.sort_values(by=['totalmo'], ascending=False, inplace=True)
    temp = temp.drop_duplicates(['id'])
    temp = temp.set_index('id')
    temp = temp[['totalmo']]
    temp.columns = ['mr_totalmo']
    data = data.join(temp, on = 'id')
    
    return data

# Calculate the surveyed opex to gross rent ratio, and fill it in for all intermediate periods between surveyed values
# Decided to consider the modeled rent level as "surveyed", since the ratio test later on will not really work if the surveyed ratio does not get updated every time a concessions quote is collected
# Example would be if we collect a survey for opex without rent that indicates the ratio is different than the lagged ratio. The code will take opex level in the surveyed period, but if the ratio isnt updated, then the next period will just be forced back into line with the lagged ratio, leading to jumps in opex that we wouldnt want to see
# Instead, all modeled rent levels should be calibrated with surveyed opex/tax values to ensure that the modeled level is reasonable given the concession survey before the beginning of this subroutine
def calc_surv_ratio(data, variable):
    temp = data.copy()
    temp = temp[(np.isnan(temp[variable]) == False)]
    temp['surv_opex_ratio'] = temp[variable] / (temp['renx'] + temp[variable])
    temp = temp[['surv_opex_ratio']]
    data = data.join(temp)
    data['surv_opex_ratio'] = np.where((data['firstrow'] == 1) & (np.isnan(data['surv_opex_ratio']) == True), 999999999, data['surv_opex_ratio'])
    data['surv_opex_ratio'] = data['surv_opex_ratio'].fillna(method='ffill')
    data['surv_opex_ratio'] = np.where(data['surv_opex_ratio'] == 999999999, np.nan, data['surv_opex_ratio'])
    
    return data

# Determine the first surveyed opex to gross rent ratio for each property
def first_surv_ratio(data):
    temp = data.copy()
    temp = temp[np.isnan(temp['surv_opex_ratio']) == False]
    temp.sort_values(by=['totalmo'], ascending=True, inplace=True)
    temp = temp.drop_duplicates(['id'])
    temp = temp.set_index('id')
    temp = temp[['surv_opex_ratio']]
    temp.columns = ['first_ratio']
    data = data.join(temp, on = 'id')
    
    return data

# Determine the most recent surveyed opex to gross rent ratio for each property
def mr_surv_ratio(data):
    temp = data.copy()
    temp = temp[np.isnan(temp['surv_opex_ratio']) == False]
    temp.sort_values(by=['totalmo'], ascending=False, inplace=True)
    temp = temp.drop_duplicates(['id'])
    temp = temp.set_index('id')
    temp = temp[['surv_opex_ratio']]
    temp.columns = ['mr_ratio']
    data = data.join(temp, on = 'id')
    
    data_after_mr = data.copy()
    data_after_mr = data_after_mr[data_after_mr['totalmo'] > data['mr_totalmo']]
    data = data[data['totalmo'] <= data['mr_totalmo']]
    
    return data, data_after_mr

# Begin modeling opex:
# First, fill in the surveyed values at each month where surveys occured
# If the first period in the historical series does not have an opex survey, then set it based on the first surveyed opex ratio.
# If there is no surveyed opex ratio for the property, then use the national average
def model_start(variable, first_surv_val, first_surv_ratio, msq_net_rent, first_row, avg_opex_ratio, sd_opex_ratio):
    
    if np.isnan(variable) == False:
        modeled = variable
    elif first_row == 1:
        if np.isnan(first_surv_val) == False and first_surv_val / (first_surv_val + msq_net_rent) > avg_opex_ratio - sd_opex_ratio and first_surv_val / (first_surv_val + msq_net_rent) < avg_opex_ratio + sd_opex_ratio:
            modeled = first_surv_val
        elif np.isnan(first_surv_ratio) == False:
            modeled = (Fraction(str(first_surv_ratio)).numerator * msq_net_rent) / (Fraction(str(first_surv_ratio)).denominator - Fraction(str(first_surv_ratio)).numerator)
        elif np.isnan(first_surv_ratio) == True:
            modeled = (Fraction(str(avg_opex_ratio)).numerator * msq_net_rent) / (Fraction(str(avg_opex_ratio)).denominator - Fraction(str(avg_opex_ratio)).numerator)
        modeled = round(modeled, 2)
    else:
        modeled = np.nan

    return modeled

# Calculate the number of months between surveyed opex values per id, as well as the raw survey to survey change between those two surveys
# Use opex_m instead of op_exp, so that we can calc the smoothing periods between the first row of the series and the first survey too. At this point, opex_m should have survey values for survey periods, as well as the modeled value in only the first period row.
# Then fill in the months between surveyed opex values at each id, as well as the survey to survey change, and calculate the portion of change per period
def forward_fill(data):

    temp = data.copy()
    temp = temp[np.isnan(temp['opex_m']) == False]
    temp['months_btw_survs'] = np.where((temp['id'] == temp['id'].shift(-1)), temp['totalmo'].shift(-1) - temp['totalmo'], np.nan)
    temp['surv_to_surv_chg'] = np.where((temp['id'] == temp['id'].shift(-1)), temp['opex_m'].shift(-1) - temp['opex_m'], np.nan)
    temp = temp[['months_btw_survs', 'surv_to_surv_chg']]
    data = data.join(temp)

    data['months_btw_survs'] = data['months_btw_survs'].fillna(method='ffill')
    data['surv_to_surv_chg'] = data['surv_to_surv_chg'].fillna(method='ffill')
    data['months_btw_survs'] = np.where((data['totalmo'] > data['mr_totalmo']) | (np.isnan(data['mr_totalmo']) == True), np.nan, data['months_btw_survs'])
    data['surv_to_surv_chg'] = np.where((data['totalmo'] > data['mr_totalmo']) | (np.isnan(data['mr_totalmo']) == True), np.nan, data['surv_to_surv_chg'])
    data['surv_portion'] = data['surv_to_surv_chg'] / data['months_btw_survs']
    data['surv_portion'] = round(data['surv_portion'], 2)

    return data

# For all periods that exist between two surveyed opex values, calculate the new opex using a smoothing method that applies an even portion of the change to each month
# This could be chunked if we want to modify that even smooth assumption
def smoothing(surv_portion, variable):
    global prev_val 
    if (np.isnan(variable) == False):
        modeled = variable
        prev_val = variable
    elif (np.isnan(surv_portion) == True):
        modeled = np.nan
        prev_val = prev_val
    else:
        modeled = prev_val + surv_portion
        prev_val = modeled
    return modeled


def opex_rent_flags(sector_val, curryr, currmon, msq_data_in):
    
    data_in = msq_data_in.copy()
    data_in = data_in[['id', 'realid', 'yr', 'qtr', 'currmon', 'type2', 'metcode', 'subid', 'survdate', 'avrent', 're_tax', 'op_exp', 'rnt_term', 'renx', 'renxM',  'taxx', 'taxxM', 'opex', 'opexM', 'availx']]

    # Test ids that have at least one opex survey collected by survey. 
    # One caveat - HSY has now decided to ignore opex surveys when they are a significant portion of surveyed rent (something around a ratio of 0.5 and up), so will remove those quotes and create a new column to tag those cases if we need to identify
    # Create a join identity, and assign a rolling consecutive count to each period per id
    data_in['high_ratio_tag'] = np.where((data_in['op_exp'] / (data_in['op_exp'] + data_in['avrent']) >= 0.5), 1, 0)
    data_in['op_exp'] = np.where(data_in['high_ratio_tag'] == 1, np.nan, data_in['op_exp'])
    data_in['op_exp'] = np.where(data_in['op_exp'] == 0, np.nan, data_in['op_exp'])
    data_in['type2'] = np.where(data_in['type2'] == "F", "F", "DW")
    data_in['identity'] = data_in['metcode'] + data_in['subid'].astype(int).astype(str) + data_in['type2']
    data = data_in.copy()
    data['firstrow'] = np.where(data['id'] != data['id'].shift(1), 1, 0)
    data['total_opex_survs'] = data.groupby('id')['op_exp'].transform('count')
    data = data[data['total_opex_survs'] > 0]
    data['identity_period'] = data['id'].astype(str) + data['yr'].astype(str) + data['qtr'].astype(str) + data['currmon'].astype(str) 
    data = data.set_index('identity_period')

    totalmo = pd.DataFrame(data.groupby('id').cumcount())
    totalmo.columns = ['totalmo']
    totalmo['totalmo'] = totalmo['totalmo'] + 1
    data = data.join(totalmo)

    # Set the average opex to gross rent ratio. Based on BBs work on the lease term data
    avg_opex_ratio = 0.30
    # Set the standard deviation to provide range for valid opex ratio
    sd_opex_ratio = 0.11
    # Set the threshold for when opex must rise from the most recent surveyed value in relation to rent (as a percent distance from the surveyed ratio)
    threshold_up = 0.03
    #Set the threshold for when opex must fall from the most recent surveyed value in relation to rent (as a percent of total rent)
    threshold_down = 0.50

    # Call the functions to finish modeling based on opex surveys only
    data = first_surv(data, 'op_exp')

    data = last_surv(data, 'op_exp')

    data = calc_surv_ratio(data, 'op_exp')

    data = first_surv_ratio(data)

    data, data_after_mr = mr_surv_ratio(data)

    data['opex_m'] = data.apply(lambda row: model_start(row['op_exp'], row['first_op_exp'], row['first_ratio'], row['renx'], row['firstrow'], avg_opex_ratio, sd_opex_ratio), axis=1)

    data = forward_fill(data)

    prev_val = np.nan
    data['opex_m'] = data.apply(lambda row: smoothing(row['surv_portion'], row['opex_m']), axis=1)

    print("Taking out tax part for now")
    # # Once all periods have an opex, we still need to test if there was a survey for tax that did not have an opex value, and that tax level indicates or lagged opex level should be adjusted
    # # Find all cases where there is only a tax survey with no opex value, and see if the tax is within an acceptable bound of the modeled opex for that period
    # # If it is not within an acceptible bound, re-model the opex based on the tax level
    # temp = data.copy()
    # temp = temp[(np.isnan(temp['re_tax']) == False) & (np.isnan(temp['op_exp']) == True)]
    # temp = temp[(temp['re_tax'] / temp['opex_m'] < 0.25) | (temp['re_tax'] / temp['opex_m'] > 0.75)]
    # temp['opex_tax'] = np.where(temp['re_tax'] / temp['opex_m'] < 0.25, temp['re_tax'] * 4, np.nan)
    # temp['opex_tax'] = np.where(temp['re_tax'] / temp['opex_m'] > 0.75, (temp['re_tax'] * 4) / 3, temp['opex_tax'])
    # temp['opex_tax'] = round(temp['opex_tax'], 2)
    # temp['tax_tag'] = np.where(np.isnan(temp['opex_tax']) == False, 1, 0)

    # temp1 = temp.copy()
    # temp1 = temp1.reset_index()
    # temp1 = temp1.set_index('identity_period')
    # temp1 = temp1[['tax_tag']]
    # temp1 = temp1[temp1['tax_tag'] == 1]
    # data = data.join(temp1)
    # data['tax_tag'] = data['tax_tag'].fillna(0)
    # data_notax = data[data['tax_tag'] == 0]
    # data_tax = data[data['tax_tag'] == 1]

    # temp = temp[['opex_tax']]
    # temp2 = data_tax.copy()
    # temp2 = temp2.join(temp)

    # temp2 = temp2[(np.isnan(temp2['opex_tax']) == False) | (np.isnan(temp2['op_exp']) == False)]
    # temp2['opex_tax'] = np.where(np.isnan(temp2['op_exp']) == False, temp2['op_exp'], temp2['opex_tax'])
    # temp2 = temp2[np.isnan(temp2['opex_tax']) == False]
    # temp2 = temp2[['opex_tax']]
    # data_tax = data_tax.join(temp2)

    # # Re-call the functions to model based on tax surveyes in addition to opex surveys
    # # Need to first drop the columns that will be recalculated based on tax surveys
    # data_tax = data_tax.drop(['mr_totalmo', 'surv_opex_ratio', 'first_ratio', 'opex_m', 'months_btw_survs', 'surv_to_surv_chg'], axis=1)

    # data_tax = last_surv(data_tax, 'opex_tax')

    # data_tax = calc_surv_ratio(data_tax, 'opex_tax')

    # data_tax = first_surv_ratio(data_tax)

    # data_tax['opex_m'] = data_tax.apply(lambda row: model_start(row['opex_tax'], row['first_op_exp'], row['first_ratio'], row['renx'], row['firstrow'], avg_opex_ratio, sd_opex_ratio), axis=1)

    # data_tax = forward_fill(data_tax)

    # prev_val = np.nan
    # data_tax['opex_m'] = data_tax.apply(lambda row: smoothing(row['surv_portion'], row['opex_tax']), axis=1)

    # prev_val = np.nan
    # data_tax['opex_m'] = data_tax.apply(lambda row: calc_subsequent(threshold_up, threshold_down, row['surv_opex_ratio'], row['first_ratio'], row['opex_tax'], row['renx'], row['g_renx']), axis=1)


    # # Now that the tax calibrations are finished, append the ids that needed a fix for tax level to the dataset with ids that did not need an adjustment
    # # And finalize the net rent level now that we have opex
    # data_notax = data_notax.append(data_tax)
    # data = data_notax.copy()

    data.sort_values(by=['id', 'yr', 'qtr', 'currmon'], inplace=True)

    # Calculate the difference between the current test opex values to the modeled values calculated by this code
    data['opex_diff_to_model'] = (data['opex_m'] - data['opex']) / data['opex']
    data['opex_diff_to_model'] = round(data['opex_diff_to_model'], 3)
    data['g_opex'] = np.where((data['id'] == data['id'].shift(1)), (data['opex'] - data['opex'].shift(1)) / data['opex'].shift(1), np.nan)
    data['g_opex_m'] = np.where((data['id'] == data['id'].shift(1)), (data['opex_m'] - data['opex_m'].shift(1)) / data['opex_m'].shift(1), np.nan)
    data['g_renx'] = np.where((data['id'] == data['id'].shift(1)), (data['renx'] - data['renx'].shift(1)) / data['renx'].shift(1), np.nan)
    data['g_opex'] = round(data['g_opex'], 3)
    data['g_opex_m'] = round(data['g_opex_m'], 3)
    data['g_renx'] = round(data['g_renx'], 3)
    data['diff_direction'] = np.where((data['g_opex'] * data['g_renx'] < 0) & (data['g_opex'] * data['g_opex_m'] < 0), 1, 0)

    # Outsheet for review
    flag_cols = ['surv_to_surv_flag', 'freq_flag', 'benchmark_flag', 'tax_flag']
    aggreg_flags = pd.DataFrame()
    data_trunc = data.copy()
    data_trunc = data_trunc[['identity', 'id', 'realid', 'yr', 'qtr', 'currmon', 'metcode', 'survdate', 'avrent', 're_tax', 'op_exp', 'rnt_term', 'renx', 'taxx', 'opex', 'months_btw_survs', 'first_op_exp', 'surv_portion', 'surv_opex_ratio', 'first_ratio', 'mr_ratio', 'opex_m', 'opex_diff_to_model', 'g_opex', 'g_opex_m', 'g_renx', 'diff_direction']]
    data_trunc['abs_diff'] = abs(data_trunc['opex_diff_to_model'])
    data_trunc.sort_values(by=['id', 'abs_diff'], ascending=[True, False], inplace=True)
    data_trunc = data_trunc[(data_trunc['abs_diff'] > 0.05) | (data_trunc['diff_direction'] == 1)]
    data_trunc.sort_values(by=['abs_diff'], ascending=[False], inplace=True)
    data_trunc = data_trunc.drop(['abs_diff'], axis=1)
    data_trunc = data_trunc.drop_duplicates('id')
    aggreg = data_trunc.copy()
    aggreg['surv_to_surv_flag'] = 1
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon', 'surv_to_surv_flag']]
    for x in flag_cols:
        if x not in list(aggreg.columns):
            aggreg[x] = 0
    aggreg_flags = aggreg_flags.append(aggreg, ignore_index=True)
    #data_trunc.to_pickle('/home/central/square/data/zzz-bb-test2/python/sq_redev/{}/{}m{}/OutputFiles/opex_quote_modeled_comp.pickle'.format(sector_val, curryr, currmon))

    # For properties that have never gotten an opex obs or for parts of the series that are after the last opex obs, analyze if the code is moving opex too often, and not in concert with rent
    test = data_in.copy()
    test['after_mr_tag'] = 0
    data_append = data_after_mr.copy()
    data_append.reset_index()
    data_append = data_append[list(data_in.columns)]
    data_append['after_mr_tag'] = 1
    test = test.append(data_append)
    test['ratio'] = test['opex'] / (test['renx'] + test['opex'])
    test['num_periods'] = test.groupby('id')['id'].transform('count')
    test['total_opex_survs'] = test.groupby('id')['op_exp'].transform('count')
    test['total_tax_survs'] = test.groupby('id')['re_tax'].transform('count')
    test = test[(test['total_opex_survs'] == 0) | (test['after_mr_tag'] == 1)]

    test['opex_chg'] = np.where((test['opex'] != test['opex'].shift(1)) & (test['id'] == test['id'].shift(1)), 1, 0)
    test['rent_chg'] = np.where((test['renx'] != test['renx'].shift(1)) & (test['id'] == test['id'].shift(1)), 1, 0)
    test['opex_num_chgs'] = test.groupby('id')['opex_chg'].transform('sum')
    test['rent_num_chgs'] = test.groupby('id')['rent_chg'].transform('sum')
    test['freq_opex_chgs'] = test['opex_num_chgs'] / test['num_periods']
    test['freq_rent_chgs'] = test['rent_num_chgs'] / test['num_periods']
    test['diff_chgs'] = test['opex_num_chgs'] - test['rent_num_chgs']
    test['chg_norentchg'] = np.where((test['opex'] != test['opex'].shift(1)) & (test['renx'] == test['renx'].shift(1)) & (test['id'] == test['id'].shift(1)), 1, 0)
    test['totchg_norentchg'] = test.groupby('id')['chg_norentchg'].transform('sum')

    test = test.drop_duplicates('id')
    test = test[['identity', 'id', 'yr', 'qtr', 'currmon', 'type2', 'metcode', 'subid', 'num_periods', 'opex_num_chgs', 'rent_num_chgs', 'freq_opex_chgs', 'freq_rent_chgs', 'diff_chgs', 'totchg_norentchg', 'after_mr_tag']]
    test = test.rename(columns={'after_mr_tag': 'has_surveyed_ratio'})
    test.sort_values(by=['diff_chgs'], ascending = [False], inplace=True)
    aggreg = test.copy()
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon']]
    aggreg['freq_flag'] = 1
    for x in flag_cols:
        if x not in list(aggreg.columns):
            aggreg[x] = 0
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon'] + flag_cols]
    aggreg_flags = aggreg_flags.append(aggreg, ignore_index=True)
    #test.to_pickle('/home/central/square/data/zzz-bb-test2/python/sq_redev/{}/{}m{}/OutputFiles/opex_noquote_concessions_freq.pickle'.format(sector_val, curryr, currmon))

    # For ids that dont have any opex or tax surveys, test if the ratio gets away from the benchmark
    test = data_in.copy()
    test['after_mr_tag'] = 0
    test['mr_ratio'] = np.nan
    data_append = data_after_mr.copy()
    data_append.reset_index()
    data_append = data_append[list(data_in.columns) + ['mr_ratio']]
    data_append['after_mr_tag'] = 1
    test = test.append(data_append)
    test['ratio'] = test['opex'] / (test['renx'] + test['opex'])
    test['total_opex_survs'] = test.groupby('id')['op_exp'].transform('count')
    test['total_tax_survs'] = test.groupby('id')['re_tax'].transform('count')
    test['out_of_ratio'] = np.where((test['ratio'] >= avg_opex_ratio + sd_opex_ratio) | (test['ratio'] < avg_opex_ratio - sd_opex_ratio) & (test['after_mr_tag'] == 0), 1, 0)
    test['out_of_ratio'] = np.where((test['ratio'] >= test['mr_ratio'] + 0.02) | (test['ratio'] < test['mr_ratio'] - 0.02) & (test['after_mr_tag'] == 1), 1, test['out_of_ratio'])
    test = test[((test['total_opex_survs'] == 0) & (test['total_tax_survs'] == 0)) | (test['after_mr_tag'] == 1)]
    test['out_of_ratio_total'] = test.groupby('id')['out_of_ratio'].transform('sum')
    test = test[test['out_of_ratio'] > 0]
    test.sort_values(by=['id', 'ratio'], ascending=[True, False], inplace=True)
    test = test.drop_duplicates('id')
    test = test[['identity', 'id', 'yr', 'qtr', 'currmon', 'type2', 'metcode', 'subid', 'ratio', 'mr_ratio', 'out_of_ratio_total', 'after_mr_tag']]
    test = test.rename(columns={'after_mr_tag': 'has_surveyed_ratio'})
    aggreg = test.copy()
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon']]
    aggreg['benchmark_flag'] = 1
    for x in flag_cols:
        if x not in list(aggreg.columns):
            aggreg[x] = 0
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon'] + flag_cols]
    aggreg_flags = aggreg_flags.append(aggreg, ignore_index=True)
    #test.to_pickle('/home/central/square/data/zzz-bb-test2/python/sq_redev/{}/{}m{}/OutputFiles/opex_noquote_ratio_test.pickle'.format(sector_val, curryr, currmon))

    # For ids that have no opex survey but that do have a tax survey, test if the opex is being estimated correctly based on the tax survey
    test = data_in.copy()
    test['after_mr_tag'] = 0
    data_append = data_after_mr.copy()
    data_append.reset_index()
    data_append = data_append[list(data_in.columns)]
    data_append['after_mr_tag'] = 1
    test = test.append(data_append)
    test['total_opex_survs'] = test.groupby('id')['op_exp'].transform('count')
    test['total_tax_survs'] = test.groupby('id')['re_tax'].transform('count')
    test['total_rent_survs'] = test.groupby('id')['avrent'].transform('count')
    test = test[((test['total_opex_survs'] == 0) & (test['total_tax_survs'] > 0) & (test['taxxM'] == 0)) | (test['after_mr_tag'] == 1)]
    test['opex_b_tax'] = test['taxx'] * 2
    test['opex_diff_expected'] = (test['opex'] - test['opex_b_tax']) / test['opex_b_tax']
    test['avrent_gross'] = np.where((np.isnan(test['avrent']) == False) & (test['rnt_term'] == "N"), test['avrent'] + test['opex_b_tax'], test['avrent'])
    test['reasonable_ratio'] = np.where((test['total_rent_survs'] == 0) & (test['opex_b_tax'] / (test['opex_b_tax'] + test['renx']) <= 0.4) & (test['opex_b_tax'] / (test['opex_b_tax'] + test['renx']) >= 0.15), 1, 0)
    test['reasonable_ratio'] = np.where((test['total_rent_survs'] > 0) & (np.isnan(test['avrent']) == False) & (test['opex_b_tax'] / test['avrent_gross'] <= 0.4) & (test['opex_b_tax'] / test['avrent_gross'] >= 0.15), 1, test['reasonable_ratio'])
    test['abs_diff'] = abs(test['opex_diff_expected'])
    test = test[(test['abs_diff'] > 0.03) & (test['reasonable_ratio'] == 1)]
    test.sort_values(by=['id', 'abs_diff'], ascending=[True, False], inplace=True)
    test = test.drop_duplicates('id')
    test = test[['identity', 'id', 'yr', 'qtr', 'currmon', 'type2', 'metcode', 'subid', 'avrent', 'taxx', 'renx', 'opex', 'opex_b_tax', 'opex_diff_expected', 'after_mr_tag']]
    test = test.rename(columns={'after_mr_tag': 'has_surveyed_ratio'})
    aggreg = test.copy()
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon']]
    aggreg['tax_flag'] = 1
    for x in flag_cols:
        if x not in list(aggreg.columns):
            aggreg[x] = 0
    aggreg = aggreg[['identity', 'id', 'yr', 'qtr', 'currmon'] + flag_cols]
    aggreg_flags = aggreg_flags.append(aggreg, ignore_index=True)
    #test.to_pickle('/home/central/square/data/zzz-bb-test2/python/sq_redev/{}/{}m{}/OutputFiles/opex_noquote_tax_test.pickle'.format(sector_val, curryr, currmon))

    aggreg_flags = aggreg_flags.reset_index(drop=True)
    aggreg_flags['flag_period'] = np.where(aggreg_flags['currmon'].isnull() == True, aggreg_flags['qtr'].astype(str) + "/" + aggreg_flags['yr'].astype(str), aggreg_flags['currmon'].astype(int).astype(str) + "/" + aggreg_flags['qtr'].astype(str) + "/" + aggreg_flags['yr'].astype(str))

    for x in flag_cols:
        aggreg_flags[x] = aggreg_flags.groupby(['id', 'flag_period'])[x].transform('sum')
        aggreg_flags[x] = np.where(aggreg_flags[x] > 0, 1, 0)
    aggreg_flags = aggreg_flags.drop_duplicates(['id', 'flag_period'])
    
    aggreg_flags.sort_values(by=['identity'], ascending=[True], inplace=True)
    aggreg_flags.to_pickle('/home/central/square/data/zzz-bb-test2/python/sq_redev/{}/{}m{}/OutputFiles/or_flags.pickle'.format(sector_val, curryr, currmon))


    return flag_cols



